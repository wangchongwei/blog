---
title: hashMap解析
date: 2019-09-03 14:01:51
tags: java
---

# HashMap 源码分析

### Hash 内部类 Node：

Node(节点)，链表中的节点，当 HashMap 数据少于 6 条时，为链表结构，Node 为其中的节点。
链表数据结构，每一个节点都记录下一个节点的地址。
在 Node 的构造函数中，直接包含了下一个节点，

```java
static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        // 将下一个节点作为入参放入构造函数中
        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
    ....

```

获取某个节点

```java

 public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab;
        Node<K,V> first, e;
        int n;
        K k;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                // 当为树结构的时候
                if (first instanceof TreeNode)
                // 获取树形结构中某个节点
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                // 遍历链表结构
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }

```

HashMap 底部是数组，数组中存放链表，当链表长度大于 6 时，转为红黑树

put：初始化 table[],使用时再初始化，避免内存。

根据 k 获取 hash，hash & length 获取 index，放入数组指定下标的链表，头插法, 链表超长 6 时，转为红黑树

## jdk1.7 及以前采用的头插法，在 jdk1.8 及以后，为避免死锁，采用尾插法。

hash & length 使用位运算符，因为位运算符快，cpu 指令就是基于位运算符，

扩容：hashmap 的初识容量是 16，每次扩容 \* 2， 为何容量取 2 的次方，因为这样在位运算时，让每一位都能使用到，效率最高，而且这样保证位运算结果与取模结果一致。

加载因子：默认 0.75，因为大量测试表明： 0.6-0.75 最佳，0.75 保证在该范围内存使用率最高。
加载因子过大时，会让 hash 碰撞概率增加，降低 hashmap 使用效率。

hashmap 使用缺点：内存使用率最高也只有 75%， hash 碰撞，极端情况退化为单链表。用空间换时间。

## 可以使用其他数据类型替代：

SparseArray： 双数组结构，key，value 分别使用数组存储， 但 SparseArray 的 key 只能为 int，
有序，通过二分查找来定位元素。
用时间换空间。
缺点： key 值只能是 int 类型

ArrayMap：sdk 19 引入，双数组结果，key 值可以为任何类型，根据 key 获取 hash，就和 SparseArray 类型一致了。
Bundle 内部就是使用 ArrayMap

## HashMap 流程

### put：

key -> hashcode -> hash -> index

根据 key 获取 hashcode， 对 hashcode 进行多次位运算获取 hash 值 h，
再根据 h 对数组 size - 1 取余 （h & （size - 1））

这样得出下标，然后遍历该下标对应链表，查询是否存在对应 key，如果存在则替换 e 对应 value，并 return oldValue
如果不存在，则在尾部插入一个新节点

tips：jdk1.7 之前是头插法，1.8 之后是尾插法

当 put 数据时，新增的话，size++，会判断是否大于临界值，大于则触发扩容

### resize

当容量>=75 时，会触发重新排列，

```java
final Node<K,V>[] resize() {
        Node<K,V>[] oldTab = table;
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        int oldThr = threshold;
        int newCap, newThr = 0;
        if (oldCap > 0) {
            if (oldCap >= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
                newThr = oldThr << 1; // double threshold
        }
        else if (oldThr > 0) // initial capacity was placed in threshold
            newCap = oldThr;
        else {               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        table = newTab;
        if (oldTab != null) {
            for (int j = 0; j < oldCap; ++j) {
                Node<K,V> e;
                if ((e = oldTab[j]) != null) {
                    oldTab[j] = null;
                    if (e.next == null)
                        newTab[e.hash & (newCap - 1)] = e;
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    else { // preserve order
                        Node<K,V> loHead = null, loTail = null;
                        Node<K,V> hiHead = null, hiTail = null;
                        Node<K,V> next;
                        do {
                            next = e.next;
                            if ((e.hash & oldCap) == 0) {
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }
```

当原数组长度已为最大值时，直接返回原数组
否则为之前数组长度的两倍，然后构建一个新的空数组 newTab，
遍历原数组，获取数组下标元素，判断下标元素类型，并会清除原数组中该下标对应值
a、原数组元素没有 next 指针，单个元素， 直接放入新数组，放入的下标会根据新数组长度重新计算：newTab[e.hash & (newCap - 1)] = e;
b、原数组元素是红黑色节点、即红黑色根结点，调用 split 函数，将红黑树放入到新数组
c、原数组又 next 指针，说明是链表，遍历链表组成新链表，并将新链表放入新数组的新位置

最后返回新数组

### 问题点

1、为何 hashmap 是非线程安全的

put 操作未加锁，在多线程时会存在异常
另外一个比较明显的线程不安全的问题是 HashMap 的 get 操作可能因为 resize 而引起死循环（cpu100%）

2、HashMap 不保证遍历的顺序和插入的顺序是一致的 为何

插入在不同的 index 时，取出的顺序与插入的顺序就不一致

3、hashmap 的效率

空间使用率最高为 75%，增删查询都是 O(1)，从空间换时间。

可以使用 SparseArray 、 ArrayMap 替代
